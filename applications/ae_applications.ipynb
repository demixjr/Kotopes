{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f608a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'Python 3.13.7' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# --- –ö–û–ù–§–Ü–ì–£–†–ê–¶–Ü–Ø ---\n",
    "FAST_MODE = True\n",
    "SUBSET_SIZE = 14500  # –¢—ñ–ª—å–∫–∏ 500 –∑–æ–±—Ä–∞–∂–µ–Ω—å –¥–ª—è —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è!\n",
    "TEST_SIZE = 1500    # –¢—ñ–ª—å–∫–∏ 100 –¥–ª—è —Ç–µ—Å—Ç—É\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 8         # –î—É–∂–µ –º–∞–ª–æ –µ–ø–æ—Ö!\n",
    "LATENT_DIM = 16    # –î—É–∂–µ –º–∞–ª–∏–π latent space\n",
    "NOISE_FACTOR = 0.3  # –†—ñ–≤–µ–Ω—å —à—É–º—É –¥–ª—è –¥–µ–Ω–æ—ó–∑–∏–Ω–≥—É\n",
    "\n",
    "# --- Cell 1: –ê–†–•–Ü–¢–ï–ö–¢–£–†–ê –ê–í–¢–û–ï–ù–ö–û–î–ï–†–ê ---\n",
    "class FastAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super(FastAutoencoder, self).__init__()\n",
    "        \n",
    "        # –ï–Ω–∫–æ–¥–µ—Ä - —Å—Ç–∏—Å–Ω–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=3, stride=2, padding=1),  # 64x64 -> 32x32\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1), # 32x32 -> 16x16\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 16 * 16, latent_dim)  # –°—Ç–∏—Å–Ω–µ–Ω–Ω—è –¥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç–æ—Ä—É\n",
    "        )\n",
    "        \n",
    "        # –î–µ–∫–æ–¥–µ—Ä - –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 16 * 16 * 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Unflatten(1, (16, 16, 16)),\n",
    "            nn.ConvTranspose2d(16, 8, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # –ù–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –ø—ñ–∫—Å–µ–ª—ñ–≤ –¥–æ [0,1]\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return self.decoder(z)\n",
    "\n",
    "# --- Cell 2: –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –î–ê–ù–ò–• ---\n",
    "def load_tiny_dataset(data_path, img_size=64):\n",
    "    \"\"\"–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –≤–∏–±—ñ—Ä–∫—É –¥–∞–Ω–∏—Ö –¥–ª—è —à–≤–∏–¥–∫–æ–≥–æ –µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    try:\n",
    "        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —á–∏ —ñ—Å–Ω—É—î —à–ª—è—Ö\n",
    "        if not os.path.exists(data_path):\n",
    "            raise FileNotFoundError(f\"–®–ª—è—Ö {data_path} –Ω–µ —ñ—Å–Ω—É—î\")\n",
    "            \n",
    "        full_dataset = ImageFolder(root=data_path, transform=transform)\n",
    "        print(f\"–£—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ: {len(full_dataset)} –∑–æ–±—Ä–∞–∂–µ–Ω—å\")\n",
    "        print(f\"   –ö–ª–∞—Å–∏: {full_dataset.classes}\")\n",
    "        \n",
    "        # –ë–µ—Ä–µ–º–æ –ª–∏—à–µ –Ω–µ–≤–µ–ª–∏–∫—É –≤–∏–±—ñ—Ä–∫—É –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ\n",
    "        total_samples = min(SUBSET_SIZE + TEST_SIZE, len(full_dataset))\n",
    "        indices = torch.randperm(len(full_dataset))[:total_samples]\n",
    "        \n",
    "        train_size = SUBSET_SIZE\n",
    "        train_indices = indices[:train_size]\n",
    "        test_indices = indices[train_size:train_size + TEST_SIZE]\n",
    "        \n",
    "        train_dataset = Subset(full_dataset, train_indices)\n",
    "        test_dataset = Subset(full_dataset, test_indices)\n",
    "        \n",
    "        print(f\" –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ: {len(train_dataset)} —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö, {len(test_dataset)} —Ç–µ—Å—Ç–æ–≤–∏—Ö\")\n",
    "        \n",
    "        return train_dataset, test_dataset, full_dataset.classes\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" –ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è: {e}\")\n",
    "        print(\"–°—Ç–≤–æ—Ä—é—î–º–æ –¥–µ–º–æ-–¥–∞–Ω—ñ.\")\n",
    "        from torchvision.datasets import FakeData\n",
    "        train_dataset = FakeData(size=SUBSET_SIZE, image_size=(3, 64, 64), num_classes=3, transform=transforms.ToTensor())\n",
    "        test_dataset = FakeData(size=TEST_SIZE, image_size=(3, 64, 64), num_classes=3, transform=transforms.ToTensor())\n",
    "        class_names = ['cat', 'dog', 'wild']\n",
    "        \n",
    "        print(f\"üìä –î–µ–º–æ-–¥–∞–Ω—ñ: {len(train_dataset)} —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö, {len(test_dataset)} —Ç–µ—Å—Ç–æ–≤–∏—Ö\")\n",
    "        \n",
    "        return train_dataset, test_dataset, class_names\n",
    "\n",
    "# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –¥–æ–¥–∞–≤–∞–Ω–Ω—è —à—É–º—É (–¥–ª—è –¥–µ–Ω–æ—ó–∑–∏–Ω–≥—É)\n",
    "def add_noise(images, noise_factor=0.3):\n",
    "    \"\"\"–î–æ–¥–∞—î –≤–∏–ø–∞–¥–∫–æ–≤–∏–π —à—É–º –¥–æ –∑–æ–±—Ä–∞–∂–µ–Ω—å\"\"\"\n",
    "    noise = torch.randn_like(images) * noise_factor\n",
    "    noisy_images = images + noise\n",
    "    return torch.clamp(noisy_images, 0.0, 1.0)\n",
    "\n",
    "# –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –¥–∞–Ω—ñ\n",
    "DATA_PATH = \"D:/Kotopes/Kotopes/data\"\n",
    "print(f\" –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –∑: {DATA_PATH}\")\n",
    "train_dataset, test_dataset, class_names = load_tiny_dataset(DATA_PATH)\n",
    "\n",
    "# --- Cell 3: –¢–†–ï–ù–£–í–ê–ù–ù–Ø –ê–í–¢–û–ï–ù–ö–û–î–ï–†–ê ---\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\" –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –ø—Ä–∏—Å—Ç—Ä—ñ–π: {device}\")\n",
    "\n",
    "model = FastAutoencoder(latent_dim=LATENT_DIM).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "def fast_train(model, train_loader, test_loader, epochs=EPOCHS, denoise_mode=False):\n",
    "    \"\"\"–¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∞–≤—Ç–æ–µ–Ω–∫–æ–¥–µ—Ä–∞ –≤ –∑–≤–∏—á–∞–π–Ω–æ–º—É –∞–±–æ –¥–µ–Ω–æ—ó–∑–∏–Ω–≥ —Ä–µ–∂–∏–º—ñ\"\"\"\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # –¢—Ä–µ–Ω—É–≤–∞–Ω–Ω—è\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for data, _ in train_loader:\n",
    "            data = data.to(device)\n",
    "            \n",
    "            if denoise_mode:\n",
    "                # –î–µ–Ω–æ—ó–∑–∏–Ω–≥: –¥–æ–¥–∞—î–º–æ —à—É–º –Ω–∞ –≤—Ö—ñ–¥, —Ü—ñ–ª—å - —á–∏—Å—Ç–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è\n",
    "                noisy_data = add_noise(data, NOISE_FACTOR)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(noisy_data)\n",
    "                loss = criterion(output, data)  # –ü–æ—Ä—ñ–≤–Ω—é—î–º–æ –∑ —á–∏—Å—Ç–∏–º –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º\n",
    "            else:\n",
    "                # –ó–≤–∏—á–∞–π–Ω–∏–π –∞–≤—Ç–æ–µ–Ω–∫–æ–¥–µ—Ä\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, data)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        mode = \"–î–ï–ù–û–á–ó–ò–ù–ì\" if denoise_mode else \"–ê–í–¢–û–ï–ù–ö–û–î–ï–†\"\n",
    "        print(f'Epoch {epoch+1}/{epochs} [{mode}]: Loss: {train_loss:.4f}')\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "print(\"–ü–æ—á–∞—Ç–æ–∫ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è –∞–≤—Ç–æ–µ–Ω–∫–æ–¥–µ—Ä–∞...\")\n",
    "train_losses = fast_train(model, train_loader, test_loader, denoise_mode=False)\n",
    "\n",
    "# --- Cell 4: –î–ï–¢–ï–ö–¶–Ü–Ø –ê–ù–û–ú–ê–õ–Ü–ô ---\n",
    "print(\"\\n===  –î–ï–¢–ï–ö–¶–Ü–Ø –ê–ù–û–ú–ê–õ–Ü–ô ===\")\n",
    "\n",
    "# –í–∏–∑–Ω–∞—á–∞—î–º–æ –Ω–æ—Ä–º–∞–ª—å–Ω–∏–π –∫–ª–∞—Å (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥, dog)\n",
    "NORMAL_CLASS = class_names.index('dog') if 'dog' in class_names else 0\n",
    "print(f\"–ù–æ—Ä–º–∞–ª—å–Ω–∏–π –∫–ª–∞—Å: {class_names[NORMAL_CLASS]}\")\n",
    "\n",
    "# –†–æ–∑–¥—ñ–ª—è—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ –Ω–∞ –Ω–æ—Ä–º–∞–ª—å–Ω—ñ —Ç–∞ –∞–Ω–æ–º–∞–ª—å–Ω—ñ\n",
    "test_normal_indices = []\n",
    "test_anomalous_indices = []\n",
    "\n",
    "for i in range(len(test_dataset)):\n",
    "    img, label = test_dataset[i]\n",
    "    if label == NORMAL_CLASS:\n",
    "        test_normal_indices.append(i)\n",
    "    else:\n",
    "        test_anomalous_indices.append(i)\n",
    "\n",
    "# –û–±–º–µ–∂—É—î–º–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ\n",
    "test_normal_indices = test_normal_indices[:20]\n",
    "test_anomalous_indices = test_anomalous_indices[:20]\n",
    "\n",
    "test_normal = Subset(test_dataset, test_normal_indices)\n",
    "test_anomalous = Subset(test_dataset, test_anomalous_indices)\n",
    "\n",
    "print(f\"–¢–µ—Å—Ç–æ–≤—ñ –¥–∞–Ω—ñ: {len(test_normal)} –Ω–æ—Ä–º–∞–ª—å–Ω–∏—Ö, {len(test_anomalous)} –∞–Ω–æ–º–∞–ª—å–Ω–∏—Ö\")\n",
    "\n",
    "# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –æ–±—á–∏—Å–ª–µ–Ω–Ω—è –ø–æ–º–∏–ª–æ–∫ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó\n",
    "def fast_errors(model, dataset, device):\n",
    "    \"\"\"–û–±—á–∏—Å–ª—é—î –ø–æ–º–∏–ª–∫–∏ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –∞–Ω–æ–º–∞–ª—ñ–π\"\"\"\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        loader = DataLoader(dataset, batch_size=32)\n",
    "        for images, _ in loader:\n",
    "            images = images.to(device)\n",
    "            reconstructed = model(images)\n",
    "            # MSE –ø–æ–º–∏–ª–∫–∞ –º—ñ–∂ –æ—Ä–∏–≥—ñ–Ω–∞–ª–æ–º —Ç–∞ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—î—é\n",
    "            error = torch.mean((images - reconstructed) ** 2, dim=[1,2,3])\n",
    "            errors.extend(error.cpu().numpy())\n",
    "    return np.array(errors)\n",
    "\n",
    "# –û–±—á–∏—Å–ª—é—î–º–æ –ø–æ–º–∏–ª–∫–∏ –¥–ª—è –Ω–æ—Ä–º–∞–ª—å–Ω–∏—Ö —Ç–∞ –∞–Ω–æ–º–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö\n",
    "normal_errors = fast_errors(model, test_normal, device)\n",
    "anomalous_errors = fast_errors(model, test_anomalous, device)\n",
    "\n",
    "# –í—Å—Ç–∞–Ω–æ–≤–ª—é—î–º–æ –ø–æ—Ä—ñ–≥ –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –∞–Ω–æ–º–∞–ª—ñ–π (95-–π –ø—Ä–æ—Ü–µ–Ω—Ç–∏–ª—å –Ω–æ—Ä–º–∞–ª—å–Ω–∏—Ö –ø–æ–º–∏–ª–æ–∫)\n",
    "threshold = np.percentile(normal_errors, 95)\n",
    "detection_rate = np.mean(anomalous_errors > threshold) * 100\n",
    "false_positive = np.mean(normal_errors > threshold) * 100\n",
    "\n",
    "print(f\" –†–ï–ó–£–õ–¨–¢–ê–¢–ò –î–ï–¢–ï–ö–¶–Ü–á –ê–ù–û–ú–ê–õ–Ü–ô:\")\n",
    "print(f\"   - –ü–æ—Ä—ñ–≥: {threshold:.4f}\")\n",
    "print(f\"   - –í–∏—è–≤–ª–µ–Ω–æ –∞–Ω–æ–º–∞–ª—ñ–π: {detection_rate:.1f}%\")\n",
    "print(f\"   - –ü–æ–º–∏–ª–∫–∞ (FPR): {false_positive:.1f}%\")\n",
    "\n",
    "# --- Cell 5: –î–ï–ù–û–á–ó–ò–ù–ì ---\n",
    "print(\"\\n=== üßπ –¢–ï–°–¢–£–í–ê–ù–ù–Ø –î–ï–ù–û–á–ó–ò–ù–ì–£ ===\")\n",
    "\n",
    "def test_denoising(model, test_samples=5):\n",
    "    \"\"\"–¢–µ—Å—Ç—É—î–º–æ –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ –≤–∏–¥–∞–ª—è—Ç–∏ —à—É–º\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # –ë–µ—Ä–µ–º–æ –¥–µ–∫—ñ–ª—å–∫–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å\n",
    "    denoise_indices = test_normal_indices[:test_samples] + test_anomalous_indices[:test_samples]\n",
    "    denoise_dataset = Subset(test_dataset, denoise_indices)\n",
    "    denoise_loader = DataLoader(denoise_dataset, batch_size=test_samples*2)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for clean_imgs, labels in denoise_loader:\n",
    "            clean_imgs = clean_imgs.to(device)\n",
    "            \n",
    "            # –î–æ–¥–∞—î–º–æ —à—É–º\n",
    "            noisy_imgs = add_noise(clean_imgs, NOISE_FACTOR)\n",
    "            \n",
    "            # –í—ñ–¥–Ω–æ–≤–ª—é—î–º–æ –∑ —à—É–º–Ω–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å\n",
    "            denoised_imgs = model(noisy_imgs)\n",
    "            \n",
    "            # –û–±—á–∏—Å–ª—é—î–º–æ —è–∫—ñ—Å—Ç—å –¥–µ–Ω–æ—ó–∑–∏–Ω–≥—É\n",
    "            mse_clean = criterion(clean_imgs, clean_imgs).item()\n",
    "            mse_noisy = criterion(noisy_imgs, clean_imgs).item()\n",
    "            mse_denoised = criterion(denoised_imgs, clean_imgs).item()\n",
    "            \n",
    "            improvement = ((mse_noisy - mse_denoised) / mse_noisy) * 100\n",
    "            \n",
    "            print(f\" –Ø–∫—ñ—Å—Ç—å –¥–µ–Ω–æ—ó–∑–∏–Ω–≥—É:\")\n",
    "            print(f\"   - MSE (—á–∏—Å—Ç—ñ): {mse_clean:.4f}\")\n",
    "            print(f\"   - MSE (—à—É–º–Ω—ñ): {mse_noisy:.4f}\")\n",
    "            print(f\"   - MSE (–≤—ñ–¥–Ω–æ–≤–ª–µ–Ω—ñ): {mse_denoised:.4f}\")\n",
    "            print(f\"   - –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è: {improvement:.1f}%\")\n",
    "            \n",
    "            return clean_imgs, noisy_imgs, denoised_imgs, labels\n",
    "\n",
    "# –¢–µ—Å—Ç—É—î–º–æ –¥–µ–Ω–æ—ó–∑–∏–Ω–≥\n",
    "clean_imgs, noisy_imgs, denoised_imgs, labels = test_denoising(model)\n",
    "\n",
    "# --- Cell 6: –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í ---\n",
    "plt.figure(figsize=(15, 4))\n",
    "\n",
    "# –ì—Ä–∞—Ñ—ñ–∫ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—è\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.plot(train_losses)\n",
    "plt.title('–í—Ç—Ä–∞—Ç–∏ –ø—Ä–∏ —Ç—Ä–µ–Ω—É–≤–∞–Ω–Ω—ñ')\n",
    "plt.xlabel('–ï–ø–æ—Ö–∞')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# –†–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫ –¥–ª—è –¥–µ—Ç–µ–∫—Ü—ñ—ó –∞–Ω–æ–º–∞–ª—ñ–π\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.hist(normal_errors, alpha=0.7, label='–ù–æ—Ä–º–∞–ª—å–Ω—ñ', bins=15, color='green')\n",
    "plt.hist(anomalous_errors, alpha=0.7, label='–ê–Ω–æ–º–∞–ª—å–Ω—ñ', bins=15, color='red')\n",
    "plt.axvline(threshold, color='black', linestyle='--', label=f'–ü–æ—Ä—ñ–≥: {threshold:.3f}')\n",
    "plt.legend()\n",
    "plt.title('–†–æ–∑–ø–æ–¥—ñ–ª –ø–æ–º–∏–ª–æ–∫ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó')\n",
    "plt.xlabel('–ü–æ–º–∏–ª–∫–∞ MSE')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# –ü—Ä–∏–∫–ª–∞–¥ —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó\n",
    "plt.subplot(1, 4, 3)\n",
    "sample_idx = 0\n",
    "sample_img, sample_label = test_dataset[sample_idx]\n",
    "sample_img = sample_img.unsqueeze(0).to(device)\n",
    "with torch.no_grad():\n",
    "    reconstructed = model(sample_img)\n",
    "\n",
    "plt.imshow(sample_img[0].cpu().permute(1, 2, 0))\n",
    "plt.title(f'–û—Ä–∏–≥—ñ–Ω–∞–ª: {class_names[sample_label]}')\n",
    "plt.axis('off')\n",
    "\n",
    "# –ü—Ä–∏–∫–ª–∞–¥ –¥–µ–Ω–æ—ó–∑–∏–Ω–≥—É\n",
    "plt.subplot(1, 4, 4)\n",
    "if clean_imgs is not None:\n",
    "    # –ü–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à–µ –≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è\n",
    "    plt.imshow(denoised_imgs[0].cpu().permute(1, 2, 0))\n",
    "    plt.title(f'–í—ñ–¥–Ω–æ–≤–ª–µ–Ω–µ (–¥–µ–Ω–æ—ó–∑–∏–Ω–≥)')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Cell 7: –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –õ–ê–¢–ï–ù–¢–ù–û–ì–û –ü–†–û–°–¢–û–†–£ ---\n",
    "print(\"\\n===  –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –õ–ê–¢–ï–ù–¢–ù–û–ì–û –ü–†–û–°–¢–û–†–£ ===\")\n",
    "\n",
    "def fast_latent_vectors(model, dataset, device, max_samples=50):\n",
    "    \"\"\"–í–∏—Ç—è–≥—É—î –ª–∞—Ç–µ–Ω—Ç–Ω—ñ –≤–µ–∫—Ç–æ—Ä–∏ –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó\"\"\"\n",
    "    model.eval()\n",
    "    latent_vectors = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        loader = DataLoader(dataset, batch_size=32)\n",
    "        for images, batch_labels in loader:\n",
    "            images = images.to(device)\n",
    "            latent = model.encoder(images)  # –°—Ç–∏—Å–Ω–µ–Ω–Ω—è –¥–æ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç–æ—Ä—É\n",
    "            latent_vectors.extend(latent.cpu().numpy())\n",
    "            labels.extend(batch_labels.numpy())\n",
    "            \n",
    "            if len(latent_vectors) >= max_samples:\n",
    "                break\n",
    "    \n",
    "    return np.array(latent_vectors)[:max_samples], np.array(labels)[:max_samples]\n",
    "\n",
    "# –í–∏—Ç—è–≥—É—î–º–æ –ª–∞—Ç–µ–Ω—Ç–Ω—ñ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è\n",
    "latent_vectors, labels = fast_latent_vectors(model, test_dataset, device)\n",
    "\n",
    "print(f\"üìä –í–∏—Ç—è–≥–Ω—É—Ç–æ {len(latent_vectors)} –ª–∞—Ç–µ–Ω—Ç–Ω–∏—Ö –≤–µ–∫—Ç–æ—Ä—ñ–≤ —Ä–æ–∑–º—ñ—Ä–Ω—ñ—Å—Ç—é {LATENT_DIM}\")\n",
    "\n",
    "# t-SNE –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç–æ—Ä—É (16D -> 2D)\n",
    "if len(latent_vectors) > 10:\n",
    "    print(\"üîç –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ t-SNE –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó...\")\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(10, len(latent_vectors)-1))\n",
    "    latent_2d = tsne.fit_transform(latent_vectors)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –∑–∞ –∫–ª–∞—Å–∞–º–∏\n",
    "    plt.subplot(1, 2, 1)\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "    for class_idx in range(len(class_names)):\n",
    "        mask = labels == class_idx\n",
    "        if np.sum(mask) > 0:\n",
    "            plt.scatter(latent_2d[mask, 0], latent_2d[mask, 1], \n",
    "                       label=class_names[class_idx], alpha=0.7, s=30)\n",
    "    plt.legend()\n",
    "    plt.title('–õ–∞—Ç–µ–Ω—Ç–Ω–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä –∑–∞ –∫–ª–∞—Å–∞–º–∏')\n",
    "    plt.xlabel('t-SNE –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')\n",
    "    plt.ylabel('t-SNE –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –Ω–æ—Ä–º–∞–ª—å–Ω—ñ vs –∞–Ω–æ–º–∞–ª—å–Ω—ñ\n",
    "    plt.subplot(1, 2, 2)\n",
    "    is_normal = (labels == NORMAL_CLASS).astype(int)\n",
    "    plt.scatter(latent_2d[is_normal==1, 0], latent_2d[is_normal==1, 1], \n",
    "               c='green', label=f'–ù–æ—Ä–º–∞–ª—å–Ω—ñ ({class_names[NORMAL_CLASS]})', alpha=0.7, s=30)\n",
    "    plt.scatter(latent_2d[is_normal==0, 0], latent_2d[is_normal==0, 1], \n",
    "               c='red', label='–ê–Ω–æ–º–∞–ª—å–Ω—ñ', alpha=0.7, s=30)\n",
    "    plt.legend()\n",
    "    plt.title('–ü–æ–¥—ñ–ª –Ω–æ—Ä–º–∞–ª—å–Ω–∏—Ö/–∞–Ω–æ–º–∞–ª—å–Ω–∏—Ö —É –ª–∞—Ç–µ–Ω—Ç–Ω–æ–º—É –ø—Ä–æ—Å—Ç–æ—Ä—ñ')\n",
    "    plt.xlabel('t-SNE –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 1')\n",
    "    plt.ylabel('t-SNE –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞ 2')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\" –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è t-SNE\")\n",
    "\n",
    "# --- Cell 8: –î–û–î–ê–¢–ö–û–í–ê –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –î–ï–ù–û–á–ó–ò–ù–ì–£ ---\n",
    "print(\"\\n=== üñºÔ∏è –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –†–ï–ó–£–õ–¨–¢–ê–¢–Ü–í –î–ï–ù–û–á–ó–ò–ù–ì–£ ===\")\n",
    "\n",
    "if clean_imgs is not None:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # –ü–æ–∫–∞–∑—É—î–º–æ –¥–µ–∫—ñ–ª—å–∫–∞ –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ –¥–µ–Ω–æ—ó–∑–∏–Ω–≥—É\n",
    "    num_examples = min(3, len(clean_imgs))\n",
    "    \n",
    "    for i in range(num_examples):\n",
    "        # –û—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è\n",
    "        plt.subplot(3, num_examples, i + 1)\n",
    "        plt.imshow(clean_imgs[i].cpu().permute(1, 2, 0))\n",
    "        plt.title(f'–û—Ä–∏–≥—ñ–Ω–∞–ª\\n{class_names[labels[i]]}')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # –ó–∞—à—É–º–ª–µ–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è\n",
    "        plt.subplot(3, num_examples, i + 1 + num_examples)\n",
    "        plt.imshow(noisy_imgs[i].cpu().permute(1, 2, 0))\n",
    "        plt.title('–ó–∞—à—É–º–ª–µ–Ω–µ')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # –í—ñ–¥–Ω–æ–≤–ª–µ–Ω–µ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è\n",
    "        plt.subplot(3, num_examples, i + 1 + 2*num_examples)\n",
    "        plt.imshow(denoised_imgs[i].cpu().permute(1, 2, 0))\n",
    "        plt.title('–í—ñ–¥–Ω–æ–≤–ª–µ–Ω–µ')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\n –ï–ö–°–ü–ï–†–ò–ú–ï–ù–¢ –ó–ê–í–ï–†–®–ï–ù–û!\")\n",
    "print(f\" –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–æ: {SUBSET_SIZE} —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö —Ç–∞ {TEST_SIZE} —Ç–µ—Å—Ç–æ–≤–∏—Ö –∑–æ–±—Ä–∞–∂–µ–Ω—å\")\n",
    "print(f\" –ö—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ø–æ—Ö: {EPOCHS}\")\n",
    "print(f\" –ö–ª–∞—Å–∏: {class_names}\")\n",
    "print(f\"–†–ï–ê–õ–Ü–ó–û–í–ê–ù–Ü –§–£–ù–ö–¶–Ü–á:\")\n",
    "print(f\"   1. –î–µ—Ç–µ–∫—Ü—ñ—è –∞–Ω–æ–º–∞–ª—ñ–π (–ø–æ—Ä—ñ–≥: {threshold:.4f})\")\n",
    "print(f\"   2. –ó–º–µ–Ω—à–µ–Ω–Ω—è —Ä–æ–∑–º—ñ—Ä–Ω–æ—Å—Ç—ñ —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è ({LATENT_DIM}D -> 2D)\")\n",
    "print(f\"   3. –î–µ–Ω–æ—ó–∑–∏–Ω–≥ –∑–æ–±—Ä–∞–∂–µ–Ω—å (—à—É–º: {NOISE_FACTOR})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
