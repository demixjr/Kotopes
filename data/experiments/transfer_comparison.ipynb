{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b69d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Transfer Learning Comparison\\n\",\n",
    "    \"## –≠—Ç–∞–ø 3: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤ transfer learning\\n\",\n",
    "    \"\\n\",\n",
    "    \"–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã:\\n\",\n",
    "    \"1. –°—Ä–∞–≤–Ω–∏–º –º–∏–Ω–∏–º—É–º 2 —Ä–∞–∑–Ω—ã–µ pretrained –º–æ–¥–µ–ª–∏ (ResNet18, VGG16)\\n\",\n",
    "    \"2. –°—Ä–∞–≤–Ω–∏–º feature extraction vs fine-tuning\\n\",\n",
    "    \"3. –ü—Ä–æ–≤–µ–¥–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å —Ä–∞–∑–Ω—ã–º–∏ learning rates\\n\",\n",
    "    \"4. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä—ã —Å different LR –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π –º–æ–¥–µ–ª–∏\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.nn as nn\\n\",\n",
    "    \"import torch.optim as optim\\n\",\n",
    "    \"from torch.utils.data import DataLoader\\n\",\n",
    "    \"from torchvision import datasets, transforms\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import time\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"from models.transfer_models import get_model\\n\",\n",
    "    \"from utils.optimizers import get_optimizer_with_different_lr, get_optimizer_simple\\n\",\n",
    "    \"from training.train_transfer import train_model, plot_training_history\\n\",\n",
    "    \"\\n\",\n",
    "    \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\",\n",
    "    \"print(f'Using device: {device}')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã\\n\",\n",
    "    \"DATA_DIR = '../data/animal_faces'\\n\",\n",
    "    \"BATCH_SIZE = 32\\n\",\n",
    "    \"NUM_EPOCHS = 15\\n\",\n",
    "    \"IMAGE_SIZE = 224\\n\",\n",
    "    \"NUM_CLASSES = 3\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏\\n\",\n",
    "    \"data_transforms = {\\n\",\n",
    "    \"    'train': transforms.Compose([\\n\",\n",
    "    \"        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\\n\",\n",
    "    \"        transforms.RandomHorizontalFlip(),\\n\",\n",
    "    \"        transforms.RandomRotation(10),\\n\",\n",
    "    \"        transforms.ToTensor(),\\n\",\n",
    "    \"        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\\n\",\n",
    "    \"    ]),\\n\",\n",
    "    \"    'val': transforms.Compose([\\n\",\n",
    "    \"        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\\n\",\n",
    "    \"        transforms.ToTensor(),\\n\",\n",
    "    \"        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\\n\",\n",
    "    \"image_datasets = {\\n\",\n",
    "    \"    x: datasets.ImageFolder(os.path.join(DATA_DIR, x), data_transforms[x])\\n\",\n",
    "    \"    for x in ['train', 'val']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataloaders = {\\n\",\n",
    "    \"    x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, \\n\",\n",
    "    \"                 shuffle=(x == 'train'), num_workers=4)\\n\",\n",
    "    \"    for x in ['train', 'val']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Train size: {len(image_datasets['train'])}\\\")\\n\",\n",
    "    \"print(f\\\"Val size: {len(image_datasets['val'])}\\\")\\n\",\n",
    "    \"print(f\\\"Classes: {image_datasets['train'].classes}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 1: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\\n\",\n",
    "    \"### –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º ResNet18 –∏ VGG16 –≤ —Ä–µ–∂–∏–º–µ feature extraction\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è\\n\",\n",
    "    \"results_architectures = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\\n\",\n",
    "    \"models_to_test = ['resnet18', 'vgg16']\\n\",\n",
    "    \"\\n\",\n",
    "    \"for model_name in models_to_test:\\n\",\n",
    "    \"    print(f\\\"\\\\n{'='*60}\\\")\\n\",\n",
    "    \"    print(f\\\"Training {model_name} with feature extraction\\\")\\n\",\n",
    "    \"    print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å\\n\",\n",
    "    \"    model = get_model(model_name, num_classes=NUM_CLASSES, \\n\",\n",
    "    \"                     pretrained=True, mode='feature_extraction')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ loss\\n\",\n",
    "    \"    criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"    optimizer = optim.Adam(model.get_trainable_params(), lr=0.001)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –û–±—É—á–µ–Ω–∏–µ\\n\",\n",
    "    \"    save_path = f'../checkpoints/transfer_{model_name}_feature_extraction.pth'\\n\",\n",
    "    \"    start_time = time.time()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    trained_model, history = train_model(\\n\",\n",
    "    \"        model, dataloaders, criterion, optimizer,\\n\",\n",
    "    \"        num_epochs=NUM_EPOCHS, device=device, \\n\",\n",
    "    \"        patience=5, save_path=save_path\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    training_time = time.time() - start_time\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\\n\",\n",
    "    \"    results_architectures[model_name] = {\\n\",\n",
    "    \"        'history': history,\\n\",\n",
    "    \"        'best_val_acc': max(history['val_acc']),\\n\",\n",
    "    \"        'training_time': training_time,\\n\",\n",
    "    \"        'mode': 'feature_extraction'\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nBest validation accuracy: {results_architectures[model_name]['best_val_acc']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Training time: {training_time/60:.2f} minutes\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"for model_name in models_to_test:\\n\",\n",
    "    \"    history = results_architectures[model_name]['history']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Loss\\n\",\n",
    "    \"    axes[0].plot(history['val_loss'], label=f'{model_name}', marker='o', markersize=4)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Accuracy\\n\",\n",
    "    \"    axes[1].plot(history['val_acc'], label=f'{model_name}', marker='o', markersize=4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[0].set_ylabel('Validation Loss')\\n\",\n",
    "    \"axes[0].set_title('Model Comparison - Validation Loss')\\n\",\n",
    "    \"axes[0].legend()\\n\",\n",
    "    \"axes[0].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[1].set_ylabel('Validation Accuracy')\\n\",\n",
    "    \"axes[1].set_title('Model Comparison - Validation Accuracy')\\n\",\n",
    "    \"axes[1].legend()\\n\",\n",
    "    \"axes[1].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../results/transfer/models_comparison.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Saved to ../results/transfer/models_comparison.png\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 2: Feature Extraction vs Fine-Tuning\\n\",\n",
    "    \"### –ë–µ—Ä–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–≤–∞ –ø–æ–¥—Ö–æ–¥–∞\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\\n\",\n",
    "    \"best_model_name = max(results_architectures, \\n\",\n",
    "    \"                     key=lambda k: results_architectures[k]['best_val_acc'])\\n\",\n",
    "    \"print(f\\\"Best model from architecture comparison: {best_model_name}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Ä–µ–∂–∏–º–æ–≤\\n\",\n",
    "    \"results_modes = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"modes = ['feature_extraction', 'fine_tuning']\\n\",\n",
    "    \"\\n\",\n",
    "    \"for mode in modes:\\n\",\n",
    "    \"    print(f\\\"\\\\n{'='*60}\\\")\\n\",\n",
    "    \"    print(f\\\"Training {best_model_name} in {mode} mode\\\")\\n\",\n",
    "    \"    print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å\\n\",\n",
    "    \"    model = get_model(best_model_name, num_classes=NUM_CLASSES, \\n\",\n",
    "    \"                     pretrained=True, mode=mode)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (–¥–ª—è fine-tuning –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω—å—à–∏–π LR)\\n\",\n",
    "    \"    criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if mode == 'feature_extraction':\\n\",\n",
    "    \"        optimizer = optim.Adam(model.get_trainable_params(), lr=0.001)\\n\",\n",
    "    \"    else:  # fine_tuning\\n\",\n",
    "    \"        optimizer = optim.Adam(model.get_trainable_params(), lr=0.0001)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –û–±—É—á–µ–Ω–∏–µ\\n\",\n",
    "    \"    save_path = f'../checkpoints/transfer_{best_model_name}_{mode}.pth'\\n\",\n",
    "    \"    start_time = time.time()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    trained_model, history = train_model(\\n\",\n",
    "    \"        model, dataloaders, criterion, optimizer,\\n\",\n",
    "    \"        num_epochs=NUM_EPOCHS, device=device, \\n\",\n",
    "    \"        patience=5, save_path=save_path\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    training_time = time.time() - start_time\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\\n\",\n",
    "    \"    results_modes[mode] = {\\n\",\n",
    "    \"        'history': history,\\n\",\n",
    "    \"        'best_val_acc': max(history['val_acc']),\\n\",\n",
    "    \"        'training_time': training_time\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nBest validation accuracy: {results_modes[mode]['best_val_acc']:.4f}\\\")\\n\",\n",
    "    \"    print(f\\\"Training time: {training_time/60:.2f} minutes\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Feature Extraction vs Fine-Tuning\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"for mode in modes:\\n\",\n",
    "    \"    history = results_modes[mode]['history']\\n\",\n",
    "    \"    label = 'Feature Extraction' if mode == 'feature_extraction' else 'Fine-Tuning'\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Loss\\n\",\n",
    "    \"    axes[0].plot(history['val_loss'], label=label, marker='o', markersize=4)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Accuracy\\n\",\n",
    "    \"    axes[1].plot(history['val_acc'], label=label, marker='o', markersize=4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[0].set_ylabel('Validation Loss')\\n\",\n",
    "    \"axes[0].set_title(f'{best_model_name}: Feature Extraction vs Fine-Tuning - Loss')\\n\",\n",
    "    \"axes[0].legend()\\n\",\n",
    "    \"axes[0].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[1].set_ylabel('Validation Accuracy')\\n\",\n",
    "    \"axes[1].set_title(f'{best_model_name}: Feature Extraction vs Fine-Tuning - Accuracy')\\n\",\n",
    "    \"axes[1].legend()\\n\",\n",
    "    \"axes[1].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../results/transfer/feature_extraction_vs_finetuning.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Saved to ../results/transfer/feature_extraction_vs_finetuning.png\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 3: –†–∞–∑–Ω—ã–µ Learning Rates\\n\",\n",
    "    \"### –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è LR –¥–ª—è feature extraction\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö LR\\n\",\n",
    "    \"results_lr = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"learning_rates = [0.0001, 0.001, 0.01]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for lr in learning_rates:\\n\",\n",
    "    \"    print(f\\\"\\\\n{'='*60}\\\")\\n\",\n",
    "    \"    print(f\\\"Training with LR = {lr}\\\")\\n\",\n",
    "    \"    print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å\\n\",\n",
    "    \"    model = get_model(best_model_name, num_classes=NUM_CLASSES, \\n\",\n",
    "    \"                     pretrained=True, mode='feature_extraction')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä\\n\",\n",
    "    \"    criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"    optimizer = optim.Adam(model.get_trainable_params(), lr=lr)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –û–±—É—á–µ–Ω–∏–µ (–º–µ–Ω—å—à–µ —ç–ø–æ—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏)\\n\",\n",
    "    \"    save_path = f'../checkpoints/transfer_lr_{lr}.pth'\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    trained_model, history = train_model(\\n\",\n",
    "    \"        model, dataloaders, criterion, optimizer,\\n\",\n",
    "    \"        num_epochs=10, device=device, \\n\",\n",
    "    \"        patience=3, save_path=save_path\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\\n\",\n",
    "    \"    results_lr[lr] = {\\n\",\n",
    "    \"        'history': history,\\n\",\n",
    "    \"        'best_val_acc': max(history['val_acc'])\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Best validation accuracy: {results_lr[lr]['best_val_acc']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–ª–∏—è–Ω–∏—è Learning Rate\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"for lr in learning_rates:\\n\",\n",
    "    \"    history = results_lr[lr]['history']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Loss\\n\",\n",
    "    \"    axes[0].plot(history['val_loss'], label=f'LR = {lr}', marker='o', markersize=4)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Accuracy\\n\",\n",
    "    \"    axes[1].plot(history['val_acc'], label=f'LR = {lr}', marker='o', markersize=4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[0].set_ylabel('Validation Loss')\\n\",\n",
    "    \"axes[0].set_title('Learning Rate Comparison - Loss')\\n\",\n",
    "    \"axes[0].legend()\\n\",\n",
    "    \"axes[0].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[1].set_ylabel('Validation Accuracy')\\n\",\n",
    "    \"axes[1].set_title('Learning Rate Comparison - Accuracy')\\n\",\n",
    "    \"axes[1].legend()\\n\",\n",
    "    \"axes[1].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../results/transfer/learning_rates.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Saved to ../results/transfer/learning_rates.png\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç 4: Different LR –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π –º–æ–¥–µ–ª–∏\\n\",\n",
    "    \"### –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞–∑–Ω—ã–µ learning rates –¥–ª—è features –∏ classifier\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è different LR\\n\",\n",
    "    \"results_different_lr = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: (base_lr –¥–ª—è features, classifier_lr –¥–ª—è classifier)\\n\",\n",
    "    \"lr_configs = [\\n\",\n",
    "    \"    (0.0001, 0.001, 'Standard (0.0001 / 0.001)'),\\n\",\n",
    "    \"    (0.00001, 0.001, 'Low Base (0.00001 / 0.001)'),\\n\",\n",
    "    \"    (0.0001, 0.01, 'High Classifier (0.0001 / 0.01)')\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for base_lr, classifier_lr, label in lr_configs:\\n\",\n",
    "    \"    print(f\\\"\\\\n{'='*60}\\\")\\n\",\n",
    "    \"    print(f\\\"Training with {label}\\\")\\n\",\n",
    "    \"    print(f\\\"{'='*60}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º–µ fine-tuning\\n\",\n",
    "    \"    model = get_model(best_model_name, num_classes=NUM_CLASSES, \\n\",\n",
    "    \"                     pretrained=True, mode='fine_tuning')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å different LR\\n\",\n",
    "    \"    criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"    optimizer = get_optimizer_with_different_lr(\\n\",\n",
    "    \"        model.model,  # –ø–µ—Ä–µ–¥–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é –º–æ–¥–µ–ª—å\\n\",\n",
    "    \"        base_lr=base_lr,\\n\",\n",
    "    \"        classifier_lr=classifier_lr,\\n\",\n",
    "    \"        optimizer_type='adam'\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –û–±—É—á–µ–Ω–∏–µ\\n\",\n",
    "    \"    save_path = f'../checkpoints/transfer_diff_lr_{base_lr}_{classifier_lr}.pth'\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    trained_model, history = train_model(\\n\",\n",
    "    \"        model, dataloaders, criterion, optimizer,\\n\",\n",
    "    \"        num_epochs=10, device=device, \\n\",\n",
    "    \"        patience=3, save_path=save_path\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\\n\",\n",
    "    \"    results_different_lr[label] = {\\n\",\n",
    "    \"        'history': history,\\n\",\n",
    "    \"        'best_val_acc': max(history['val_acc']),\\n\",\n",
    "    \"        'base_lr': base_lr,\\n\",\n",
    "    \"        'classifier_lr': classifier_lr\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"Best validation accuracy: {results_different_lr[label]['best_val_acc']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è Different LR\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"for label in results_different_lr.keys():\\n\",\n",
    "    \"    history = results_different_lr[label]['history']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Loss\\n\",\n",
    "    \"    axes[0].plot(history['val_loss'], label=label, marker='o', markersize=4)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Accuracy\\n\",\n",
    "    \"    axes[1].plot(history['val_acc'], label=label, marker='o', markersize=4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[0].set_ylabel('Validation Loss')\\n\",\n",
    "    \"axes[0].set_title('Different LR Comparison - Loss')\\n\",\n",
    "    \"axes[0].legend()\\n\",\n",
    "    \"axes[0].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[1].set_ylabel('Validation Accuracy')\\n\",\n",
    "    \"axes[1].set_title('Different LR Comparison - Accuracy')\\n\",\n",
    "    \"axes[1].legend()\\n\",\n",
    "    \"axes[1].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../results/transfer/different_lr_comparison.png', dpi=300, bbox_inches='tight')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Saved to ../results/transfer/different_lr_comparison.png\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. –§–∏–Ω–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\\n\",\n",
    "    \"final_results = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞–º\\n\",\n",
    "    \"for model_name in models_to_test:\\n\",\n",
    "    \"    final_results.append({\\n\",\n",
    "    \"        'Experiment': f'{model_name} (Feature Extraction)',\\n\",\n",
    "    \"        'Best Val Accuracy': f\\\"{results_architectures[model_name]['best_val_acc']:.4f}\\\",\\n\",\n",
    "    \"        'Training Time (min)': f\\\"{results_architectures[model_name]['training_time']/60:.2f}\\\"\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Feature Extraction vs Fine-Tuning\\n\",\n",
    "    \"for mode in modes:\\n\",\n",
    "    \"    final_results.append({\\n\",\n",
    "    \"        'Experiment': f'{best_model_name} ({mode.replace(\\\"_\\\", \\\" \\\").title()})',\\n\",\n",
    "    \"        'Best Val Accuracy': f\\\"{results_modes[mode]['best_val_acc']:.4f}\\\",\\n\",\n",
    "    \"        'Training Time (min)': f\\\"{results_modes[mode]['training_time']/60:.2f}\\\"\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ LR\\n\",\n",
    "    \"for lr in learning_rates:\\n\",\n",
    "    \"    final_results.append({\\n\",\n",
    "    \"        'Experiment': f'{best_model_name} (LR={lr})',\\n\",\n",
    "    \"        'Best Val Accuracy': f\\\"{results_lr[lr]['best_val_acc']:.4f}\\\",\\n\",\n",
    "    \"        'Training Time (min)': '-'\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –†–µ–∑—É–ª—å—Ç–∞—Ç—ã Different LR\\n\",\n",
    "    \"for label in results_different_lr.keys():\\n\",\n",
    "    \"    final_results.append({\\n\",\n",
    "    \"        'Experiment': f'Different LR: {label}',\\n\",\n",
    "    \"        'Best Val Accuracy': f\\\"{results_different_lr[label]['best_val_acc']:.4f}\\\",\\n\",\n",
    "    \"        'Training Time (min)': '-'\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –°–æ–∑–¥–∞–µ–º DataFrame\\n\",\n",
    "    \"df_results = pd.DataFrame(final_results)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\\n\",\n",
    "    \"print(\\\"FINAL TRANSFER LEARNING RESULTS\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"print(df_results.to_string(index=False))\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª\\n\",\n",
    "    \"df_results.to_csv('../results/transfer/final_results.txt', index=False, sep='\\\\t')\\n\",\n",
    "    \"print(\\\"\\\\nSaved to ../results/transfer/final_results.txt\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é\\n\",\n",
    "    \"best_config = max(final_results, key=lambda x: float(x['Best Val Accuracy']))\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüèÜ BEST CONFIGURATION:\\\")\\n\",\n",
    "    \"print(f\\\"   Experiment: {best_config['Experiment']}\\\")\\n\",\n",
    "    \"print(f\\\"   Validation Accuracy: {best_config['Best Val Accuracy']}\\\")\\n\",\n",
    "    \"print(f\\\"   Training Time: {best_config['Training Time (min)']} minutes\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. –í—ã–≤–æ–¥—ã\\n\",\n",
    "    \"\\n\",\n",
    "    \"–í —ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ –º—ã:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **–°—Ä–∞–≤–Ω–∏–ª–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã**: ResNet18 vs VGG16\\n\",\n",
    "    \"   - –û–ø—Ä–µ–¥–µ–ª–∏–ª–∏, –∫–∞–∫–∞—è –º–æ–¥–µ–ª—å –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –Ω–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **Feature Extraction vs Fine-Tuning**:\\n\",\n",
    "    \"   - Feature Extraction: –±—ã—Å—Ç—Ä–µ–µ –æ–±—É—á–∞–µ—Ç—Å—è, –Ω–æ –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –Ω–∏–∂–µ —Ç–æ—á–Ω–æ—Å—Ç—å\\n\",\n",
    "    \"   - Fine-Tuning: –º–µ–¥–ª–µ–Ω–Ω–µ–µ, –Ω–æ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ª—É—á—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å Learning Rate**:\\n\",\n",
    "    \"   - –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∏ —Ä–∞–∑–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è LR\\n\",\n",
    "    \"   - –ù–∞—à–ª–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π LR –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏\\n\",\n",
    "    \"\\n\",\n",
    "    \"4. **Different LR –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π –º–æ–¥–µ–ª–∏**:\\n\",\n",
    "    \"   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ —Ä–∞–∑–Ω—ã–µ LR –¥–ª—è features –∏ classifier\\n\",\n",
    "    \"   - –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –±–æ–ª–µ–µ –∞–∫–∫—É—Ä–∞—Ç–Ω–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å pretrained –º–æ–¥–µ–ª—å\\n\",\n",
    "    \"\\n\",\n",
    "    \"–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ `../checkpoints/transfer_best.pth`\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
