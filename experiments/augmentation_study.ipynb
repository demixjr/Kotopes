{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2591e",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Augmentation and Regularization Study\\n\",\n",
    "    \"## Этап 4: Борьба с переобучением\\n\",\n",
    "    \"\\n\",\n",
    "    \"В этом ноутбуке:\\n\",\n",
    "    \"1. Сравним базовую и продвинутую аугментацию\\n\",\n",
    "    \"2. Протестируем разные виды регуляризации\\n\",\n",
    "    \"3. Создадим ensemble моделей\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import torch\\n\",\n",
    "    \"import torch.nn as nn\\n\",\n",
    "    \"import torch.optim as optim\\n\",\n",
    "    \"from torch.utils.data import DataLoader\\n\",\n",
    "    \"from torchvision import datasets\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"sys.path.append('..')\\n\",\n",
    "    \"\\n\",\n",
    "    \"from models.transfer_models import get_model\\n\",\n",
    "    \"from augmentation.baseline_aug import get_baseline_transforms\\n\",\n",
    "    \"from augmentation.advanced_aug import get_advanced_transforms\\n\",\n",
    "    \"from utils.regularizers import LabelSmoothingCrossEntropy\\n\",\n",
    "    \"from training.train_regularization import train_with_regularization\\n\",\n",
    "    \"\\n\",\n",
    "    \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\",\n",
    "    \"print(f'Device: {device}')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Эксперимент: Baseline vs Advanced Augmentation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Параметры\\n\",\n",
    "    \"DATA_DIR = '../data/animal_faces'\\n\",\n",
    "    \"BATCH_SIZE = 32\\n\",\n",
    "    \"NUM_EPOCHS = 5\\n\",\n",
    "    \"NUM_CLASSES = 3\\n\",\n",
    "    \"IMAGE_SIZE = 224\\n\",\n",
    "    \"\\n\",\n",
    "    \"results_augmentation = {}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Тест 1: Baseline Augmentation\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"BASELINE AUGMENTATION\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"transforms_dict = get_baseline_transforms(IMAGE_SIZE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"image_datasets = {\\n\",\n",
    "    \"    x: datasets.ImageFolder(os.path.join(DATA_DIR, x), transforms_dict[x])\\n\",\n",
    "    \"    for x in ['train', 'val']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataloaders = {\\n\",\n",
    "    \"    x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, \\n\",\n",
    "    \"                 shuffle=(x == 'train'), num_workers=0)\\n\",\n",
    "    \"    for x in ['train', 'val']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"model = get_model('resnet18', num_classes=NUM_CLASSES, pretrained=True, mode='fine_tuning')\\n\",\n",
    "    \"criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"optimizer = optim.Adam(model.parameters(), lr=0.0001)\\n\",\n",
    "    \"\\n\",\n",
    "    \"model, history = train_with_regularization(\\n\",\n",
    "    \"    model, dataloaders, criterion, optimizer,\\n\",\n",
    "    \"    num_epochs=NUM_EPOCHS, device=device,\\n\",\n",
    "    \"    save_path='../checkpoints/baseline_aug.pth'\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"results_augmentation['baseline'] = {\\n\",\n",
    "    \"    'history': history,\\n\",\n",
    "    \"    'best_val_acc': max(history['val_acc'])\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nBest Val Acc: {results_augmentation['baseline']['best_val_acc']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Тест 2: Advanced Augmentation\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"ADVANCED AUGMENTATION\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"transforms_dict = get_advanced_transforms(IMAGE_SIZE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"image_datasets = {\\n\",\n",
    "    \"    x: datasets.ImageFolder(os.path.join(DATA_DIR, x), transforms_dict[x])\\n\",\n",
    "    \"    for x in ['train', 'val']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataloaders = {\\n\",\n",
    "    \"    x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, \\n\",\n",
    "    \"                 shuffle=(x == 'train'), num_workers=0)\\n\",\n",
    "    \"    for x in ['train', 'val']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"model = get_model('resnet18', num_classes=NUM_CLASSES, pretrained=True, mode='fine_tuning')\\n\",\n",
    "    \"criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"optimizer = optim.Adam(model.parameters(), lr=0.0001)\\n\",\n",
    "    \"\\n\",\n",
    "    \"model, history = train_with_regularization(\\n\",\n",
    "    \"    model, dataloaders, criterion, optimizer,\\n\",\n",
    "    \"    num_epochs=NUM_EPOCHS, device=device,\\n\",\n",
    "    \"    save_path='../checkpoints/advanced_aug.pth'\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"results_augmentation['advanced'] = {\\n\",\n",
    "    \"    'history': history,\\n\",\n",
    "    \"    'best_val_acc': max(history['val_acc'])\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nBest Val Acc: {results_augmentation['advanced']['best_val_acc']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Визуализация: Baseline vs Advanced\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"for aug_type in ['baseline', 'advanced']:\\n\",\n",
    "    \"    history = results_augmentation[aug_type]['history']\\n\",\n",
    "    \"    label = aug_type.capitalize()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    axes[0].plot(history['val_loss'], label=label, marker='o')\\n\",\n",
    "    \"    axes[1].plot(history['val_acc'], label=label, marker='o')\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[0].set_ylabel('Validation Loss')\\n\",\n",
    "    \"axes[0].set_title('Augmentation Comparison - Loss')\\n\",\n",
    "    \"axes[0].legend()\\n\",\n",
    "    \"axes[0].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[1].set_ylabel('Validation Accuracy')\\n\",\n",
    "    \"axes[1].set_title('Augmentation Comparison - Accuracy')\\n\",\n",
    "    \"axes[1].legend()\\n\",\n",
    "    \"axes[1].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../results/augmentation/augmentation_comparison.png', dpi=300)\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Saved to ../results/augmentation/augmentation_comparison.png\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Эксперимент: Разные виды регуляризации\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"results_regularization = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Используем базовую аугментацию для всех\\n\",\n",
    "    \"transforms_dict = get_baseline_transforms(IMAGE_SIZE)\\n\",\n",
    "    \"\\n\",\n",
    "    \"image_datasets = {\\n\",\n",
    "    \"    x: datasets.ImageFolder(os.path.join(DATA_DIR, x), transforms_dict[x])\\n\",\n",
    "    \"    for x in ['train', 'val']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataloaders = {\\n\",\n",
    "    \"    x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, \\n\",\n",
    "    \"                 shuffle=(x == 'train'), num_workers=0)\\n\",\n",
    "    \"    for x in ['train', 'val']\\n\",\n",
    "    \"}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Тест 1: Без регуляризации\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"NO REGULARIZATION\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"model = get_model('resnet18', num_classes=NUM_CLASSES, pretrained=True, mode='fine_tuning')\\n\",\n",
    "    \"criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"optimizer = optim.Adam(model.parameters(), lr=0.0001)\\n\",\n",
    "    \"\\n\",\n",
    "    \"model, history = train_with_regularization(\\n\",\n",
    "    \"    model, dataloaders, criterion, optimizer,\\n\",\n",
    "    \"    num_epochs=NUM_EPOCHS, device=device,\\n\",\n",
    "    \"    save_path='../checkpoints/no_reg.pth'\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"results_regularization['no_reg'] = {\\n\",\n",
    "    \"    'history': history,\\n\",\n",
    "    \"    'best_val_acc': max(history['val_acc'])\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Best Val Acc: {results_regularization['no_reg']['best_val_acc']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Тест 2: Weight Decay (L2)\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"WEIGHT DECAY (L2)\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"model = get_model('resnet18', num_classes=NUM_CLASSES, pretrained=True, mode='fine_tuning')\\n\",\n",
    "    \"criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.001)  # L2\\n\",\n",
    "    \"\\n\",\n",
    "    \"model, history = train_with_regularization(\\n\",\n",
    "    \"    model, dataloaders, criterion, optimizer,\\n\",\n",
    "    \"    num_epochs=NUM_EPOCHS, device=device,\\n\",\n",
    "    \"    save_path='../checkpoints/l2_reg.pth'\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"results_regularization['l2'] = {\\n\",\n",
    "    \"    'history': history,\\n\",\n",
    "    \"    'best_val_acc': max(history['val_acc'])\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Best Val Acc: {results_regularization['l2']['best_val_acc']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Тест 3: Label Smoothing\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"LABEL SMOOTHING\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"model = get_model('resnet18', num_classes=NUM_CLASSES, pretrained=True, mode='fine_tuning')\\n\",\n",
    "    \"criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\\n\",\n",
    "    \"optimizer = optim.Adam(model.parameters(), lr=0.0001)\\n\",\n",
    "    \"\\n\",\n",
    "    \"model, history = train_with_regularization(\\n\",\n",
    "    \"    model, dataloaders, criterion, optimizer,\\n\",\n",
    "    \"    num_epochs=NUM_EPOCHS, device=device,\\n\",\n",
    "    \"    save_path='../checkpoints/label_smoothing.pth'\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"results_regularization['label_smoothing'] = {\\n\",\n",
    "    \"    'history': history,\\n\",\n",
    "    \"    'best_val_acc': max(history['val_acc'])\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Best Val Acc: {results_regularization['label_smoothing']['best_val_acc']:.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Визуализация регуляризации\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"labels_map = {\\n\",\n",
    "    \"    'no_reg': 'No Regularization',\\n\",\n",
    "    \"    'l2': 'Weight Decay (L2)',\\n\",\n",
    "    \"    'label_smoothing': 'Label Smoothing'\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for reg_type, label in labels_map.items():\\n\",\n",
    "    \"    history = results_regularization[reg_type]['history']\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    axes[0].plot(history['val_loss'], label=label, marker='o')\\n\",\n",
    "    \"    axes[1].plot(history['val_acc'], label=label, marker='o')\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[0].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[0].set_ylabel('Validation Loss')\\n\",\n",
    "    \"axes[0].set_title('Regularization Comparison - Loss')\\n\",\n",
    "    \"axes[0].legend()\\n\",\n",
    "    \"axes[0].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"axes[1].set_xlabel('Epoch')\\n\",\n",
    "    \"axes[1].set_ylabel('Validation Accuracy')\\n\",\n",
    "    \"axes[1].set_title('Regularization Comparison - Accuracy')\\n\",\n",
    "    \"axes[1].legend()\\n\",\n",
    "    \"axes[1].grid(True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../results/augmentation/regularization_study.png', dpi=300)\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Saved to ../results/augmentation/regularization_study.png\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Ensemble моделей\\n\",\n",
    "    \"### Объединяем несколько моделей для лучших результатов\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Обучим 3 разные модели\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"TRAINING ENSEMBLE MODELS\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"ensemble_models = []\\n\",\n",
    "    \"model_names = ['resnet18', 'vgg16', 'mobilenet_v2']\\n\",\n",
    "    \"\\n\",\n",
    "    \"transforms_dict = get_baseline_transforms(IMAGE_SIZE)\\n\",\n",
    "    \"image_datasets = {\\n\",\n",
    "    \"    x: datasets.ImageFolder(os.path.join(DATA_DIR, x), transforms_dict[x])\\n\",\n",
    "    \"    for x in ['train', 'val']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"dataloaders = {\\n\",\n",
    "    \"    x: DataLoader(image_datasets[x], batch_size=BATCH_SIZE, \\n\",\n",
    "    \"                 shuffle=(x == 'train'), num_workers=0)\\n\",\n",
    "    \"    for x in ['train', 'val']\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for model_name in model_names:\\n\",\n",
    "    \"    print(f\\\"\\\\nTraining {model_name}...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    model = get_model(model_name, num_classes=NUM_CLASSES, pretrained=True, mode='fine_tuning')\\n\",\n",
    "    \"    criterion = nn.CrossEntropyLoss()\\n\",\n",
    "    \"    optimizer = optim.Adam(model.parameters(), lr=0.0001)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    model, _ = train_with_regularization(\\n\",\n",
    "    \"        model, dataloaders, criterion, optimizer,\\n\",\n",
    "    \"        num_epochs=3,  # Меньше эпох для ансамбля\\n\",\n",
    "    \"        device=device,\\n\",\n",
    "    \"        save_path=f'../checkpoints/ensemble_{model_name}.pth'\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ensemble_models.append(model)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Тестируем ансамбль\\n\",\n",
    "    \"def evaluate_ensemble(models, dataloader, device):\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    Оценка ансамбля моделей\\n\",\n",
    "    \"    \\\"\\\"\\\"\\n\",\n",
    "    \"    for model in models:\\n\",\n",
    "    \"        model.eval()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    correct = 0\\n\",\n",
    "    \"    total = 0\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        for inputs, labels in dataloader:\\n\",\n",
    "    \"            inputs = inputs.to(device)\\n\",\n",
    "    \"            labels = labels.to(device)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Получаем предсказания от всех моделей\\n\",\n",
    "    \"            outputs_list = [model(inputs) for model in models]\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            # Усредняем предсказания\\n\",\n",
    "    \"            outputs_avg = torch.stack(outputs_list).mean(dim=0)\\n\",\n",
    "    \"            \\n\",\n",
    "    \"            _, preds = torch.max(outputs_avg, 1)\\n\",\n",
    "    \"            total += labels.size(0)\\n\",\n",
    "    \"            correct += (preds == labels).sum().item()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    accuracy = correct / total\\n\",\n",
    "    \"    return accuracy\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Оценка отдельных моделей\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"SINGLE MODEL vs ENSEMBLE\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"single_accuracies = []\\n\",\n",
    "    \"for i, model_name in enumerate(model_names):\\n\",\n",
    "    \"    acc = evaluate_ensemble([ensemble_models[i]], dataloaders['val'], device)\\n\",\n",
    "    \"    single_accuracies.append(acc)\\n\",\n",
    "    \"    print(f\\\"{model_name}: {acc:.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Оценка ансамбля\\n\",\n",
    "    \"ensemble_acc = evaluate_ensemble(ensemble_models, dataloaders['val'], device)\\n\",\n",
    "    \"print(f\\\"\\\\nEnsemble: {ensemble_acc:.4f}\\\")\\n\",\n",
    "    \"print(f\\\"Improvement: +{(ensemble_acc - max(single_accuracies)):.4f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Визуализация: Single vs Ensemble\\n\",\n",
    "    \"fig, ax = plt.subplots(figsize=(10, 6))\\n\",\n",
    "    \"\\n\",\n",
    "    \"x_labels = model_names + ['Ensemble']\\n\",\n",
    "    \"accuracies = single_accuracies + [ensemble_acc]\\n\",\n",
    "    \"colors = ['skyblue', 'skyblue', 'skyblue', 'coral']\\n\",\n",
    "    \"\\n\",\n",
    "    \"bars = ax.bar(x_labels, accuracies, color=colors, edgecolor='black')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Добавляем значения на столбцы\\n\",\n",
    "    \"for bar in bars:\\n\",\n",
    "    \"    height = bar.get_height()\\n\",\n",
    "    \"    ax.text(bar.get_x() + bar.get_width()/2., height,\\n\",\n",
    "    \"            f'{height:.4f}',\\n\",\n",
    "    \"            ha='center', va='bottom', fontsize=11, fontweight='bold')\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax.set_ylabel('Validation Accuracy', fontsize=12)\\n\",\n",
    "    \"ax.set_title('Single Models vs Ensemble', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"ax.set_ylim([min(accuracies) - 0.02, max(accuracies) + 0.02])\\n\",\n",
    "    \"ax.grid(axis='y', alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.savefig('../results/augmentation/ensemble_vs_single.png', dpi=300)\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Saved to ../results/augmentation/ensemble_vs_single.png\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Итоговая таблица результатов\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Создаем итоговую таблицу\\n\",\n",
    "    \"final_results = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Аугментация\\n\",\n",
    "    \"for aug_type in ['baseline', 'advanced']:\\n\",\n",
    "    \"    final_results.append({\\n\",\n",
    "    \"        'Experiment': f'{aug_type.capitalize()} Augmentation',\\n\",\n",
    "    \"        'Best Val Accuracy': f\\\"{results_augmentation[aug_type]['best_val_acc']:.4f}\\\"\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Регуляризация\\n\",\n",
    "    \"for reg_type, label in labels_map.items():\\n\",\n",
    "    \"    final_results.append({\\n\",\n",
    "    \"        'Experiment': label,\\n\",\n",
    "    \"        'Best Val Accuracy': f\\\"{results_regularization[reg_type]['best_val_acc']:.4f}\\\"\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Ансамбль\\n\",\n",
    "    \"for i, model_name in enumerate(model_names):\\n\",\n",
    "    \"    final_results.append({\\n\",\n",
    "    \"        'Experiment': f'Single: {model_name}',\\n\",\n",
    "    \"        'Best Val Accuracy': f\\\"{single_accuracies[i]:.4f}\\\"\\n\",\n",
    "    \"    })\\n\",\n",
    "    \"\\n\",\n",
    "    \"final_results.append({\\n\",\n",
    "    \"    'Experiment': 'Ensemble (3 models)',\\n\",\n",
    "    \"    'Best Val Accuracy': f\\\"{ensemble_acc:.4f}\\\"\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_results = pd.DataFrame(final_results)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*80)\\n\",\n",
    "    \"print(\\\"FINAL AUGMENTATION & REGULARIZATION RESULTS\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"print(df_results.to_string(index=False))\\n\",\n",
    "    \"print(\\\"=\\\"*80)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_results.to_csv('../results/augmentation/final_results.txt', index=False, sep='\\\\t')\\n\",\n",
    "    \"print(\\\"\\\\nSaved to ../results/augmentation/final_results.txt\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Выводы\\n\",\n",
    "    \"\\n\",\n",
    "    \"В этом ноутбуке мы:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Сравнили аугментацию**:\\n\",\n",
    "    \"   - Baseline: простые трансформации\\n\",\n",
    "    \"   - Advanced: больше вариативности данных\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. **Протестировали регуляризацию**:\\n\",\n",
    "    \"   - Weight Decay (L2): штрафует большие веса\\n\",\n",
    "    \"   - Label Smoothing: делает модель менее уверенной\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **Создали ансамбль моделей**:\\n\",\n",
    "    \"   - Объединили ResNet18, VGG16, MobileNetV2\\n\",\n",
    "    \"   - Ансамбль обычно точнее одной модели\\n\",\n",
    "    \"\\n\",\n",
    "    \"Лучшая модель сохранена в `../checkpoints/augmented_best.pth`\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
